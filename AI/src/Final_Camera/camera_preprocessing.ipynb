{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#1.Import"],"metadata":{"id":"dddq0dnE5iTv"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"fLSVvx43lBa9"},"outputs":[],"source":["import csv\n","import cv2\n","import itertools\n","import numpy as np\n","import pandas as pd\n","import os\n","import sys\n","import tempfile\n","\n","import tensorflow as tf\n","from enum import Enum\n","from tqdm import tqdm\n","\n","from matplotlib import pyplot as plt\n","from matplotlib.collections import LineCollection\n","\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","from tensorflow import keras\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"]},{"cell_type":"markdown","source":["#2.Drive mount"],"metadata":{"id":"D8vd2KeB5lnm"}},{"cell_type":"code","source":["from google.colab import drive\n","\n","drive.mount('/content/drive/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ObXDni6AljPz","executionInfo":{"status":"ok","timestamp":1687937428035,"user_tz":-540,"elapsed":15990,"user":{"displayName":"yen jo","userId":"06263907903495489364"}},"outputId":"c3277ce8-62d7-4371-a646-2d68d1fe71d4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}]},{"cell_type":"code","source":["image_path = \"/content/drive/MyDrive/Wi-Fi/camera_preprocessing/photo_1.jpg\"\n","csv_out_path = \"/content/drive/MyDrive/Wi-Fi/camera_preprocessing/output.csv\"\n","images_out_folder = \"/content/drive/MyDrive/Wi-Fi/camera_preprocessing\"\n","model_path = \"/content/drive/MyDrive/Wi-Fi/camera_preprocessing/movenet_thunder.tflite\""],"metadata":{"id":"kxGSz5wIlClF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#3.PreProcessing Function"],"metadata":{"id":"GmdeJstu58l4"}},{"cell_type":"code","source":["\n","class BodyPart(Enum):\n","    \"\"\"Body part names for each keypoint.\"\"\"\n","    NOSE = 0\n","    LEFT_EYE = 1\n","    RIGHT_EYE = 2\n","    LEFT_EAR = 3\n","    RIGHT_EAR = 4\n","    LEFT_SHOULDER = 5\n","    RIGHT_SHOULDER = 6\n","    LEFT_ELBOW = 7\n","    RIGHT_ELBOW = 8\n","    LEFT_WRIST = 9\n","    RIGHT_WRIST = 10\n","    LEFT_HIP = 11\n","    RIGHT_HIP = 12\n","    LEFT_KNEE = 13\n","    RIGHT_KNEE = 14\n","    LEFT_ANKLE = 15\n","    RIGHT_ANKLE = 16\n","\n","def load_movenet_model(model_path):\n","    \"\"\"Loads the MoveNet model from the given .tflite file.\n","\n","    Args:\n","        model_path: Path to the MoveNet .tflite file.\n","\n","    Returns:\n","        Loaded MoveNet interpreter.\n","    \"\"\"\n","    interpreter = tf.lite.Interpreter(model_path=model_path)\n","    interpreter.allocate_tensors()\n","    return interpreter\n","\n","def detect_landmarks(image, interpreter):\n","    \"\"\"Detects landmarks in the given image using the MoveNet model.\n","\n","    Args:\n","        image: Input image in RGB format.\n","        interpreter: MoveNet interpreter.\n","\n","    Returns:\n","        Detected landmarks.\n","    \"\"\"\n","    input_details = interpreter.get_input_details()\n","    output_details = interpreter.get_output_details()\n","\n","    input_shape = input_details[0]['shape']\n","    input_tensor = np.expand_dims(image, axis=0)\n","    input_tensor = tf.image.resize(input_tensor, (input_shape[1], input_shape[2]))\n","    input_tensor = tf.cast(input_tensor, dtype=input_details[0]['dtype'])\n","\n","    interpreter.set_tensor(input_details[0]['index'], input_tensor)\n","    interpreter.invoke()\n","\n","    output_tensor = interpreter.get_tensor(output_details[0]['index'])\n","    landmarks = output_tensor.squeeze()\n","    print(landmarks)\n","    return landmarks\n","\n","def preprocess_single_image(image_path, csv_out_path, images_out_folder, model_path, detection_threshold=0.1):\n","    \"\"\"Preprocesses a single image and saves the detected landmarks in a CSV file.\n","\n","    Args:\n","        image_path: Path to the input image.\n","        csv_out_path: Path to write the CSV file containing the detected landmark\n","            coordinates.\n","        images_out_folder: Path to write the image overlay with detected\n","            landmarks.\n","        model_path: Path to the MoveNet .tflite file.\n","        detection_threshold: Only keep the image if all landmark confidence scores\n","            are above this threshold.\n","    \"\"\"\n","    # Load the image\n","    try:\n","        image = tf.io.read_file(image_path)\n","        image = tf.io.decode_jpeg(image)\n","    except:\n","        raise ValueError(f\"Invalid image: {image_path}\")\n","\n","    image_height, image_width, channel = image.shape\n","\n","    # Skip images that aren't RGB because MoveNet requires RGB images\n","    if channel != 3:\n","        raise ValueError(f\"Image isn't in RGB format: {image_path}\")\n","\n","\n","    # Load the MoveNet model\n","    interpreter = load_movenet_model(model_path)\n","\n","    # Detect landmarks using MoveNet\n","    landmarks = detect_landmarks(image, interpreter)\n","\n","    # Write the landmark coordinates to the CSV file\n","    with open(csv_out_path, \"w\") as csv_out_file:\n","        csv_out_writer = csv.writer(csv_out_file, delimiter=\",\", quoting=csv.QUOTE_MINIMAL)\n","        coordinates = landmarks.flatten().astype(str).tolist()\n","        csv_out_writer.writerow([os.path.basename(image_path)] + coordinates)\n"],"metadata":{"id":"7m5KC2wQ2CiE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["preprocess_single_image(image_path, csv_out_path, images_out_folder, model_path)\n","# 각각의 좌표값"],"metadata":{"id":"c9uvXzJj1oD0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687937435702,"user_tz":-540,"elapsed":2547,"user":{"displayName":"yen jo","userId":"06263907903495489364"}},"outputId":"9d544b66-e462-47e6-e325-e98cdfdbae20"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.02797922 0.49135107 0.01280772]\n"," [0.01546238 0.5675123  0.00785297]\n"," [0.01129412 0.46207592 0.01420071]\n"," [0.00710539 0.67704993 0.0197892 ]\n"," [0.00119213 0.47105625 0.01207166]\n"," [0.01198644 0.7015546  0.02657878]\n"," [0.00808639 0.50048876 0.02618898]\n"," [0.48540503 0.8064845  0.03578768]\n"," [0.5131134  0.34670332 0.01114855]\n"," [0.6355806  0.8317252  0.01557579]\n"," [0.6497566  0.35922277 0.00938828]\n"," [0.6646994  0.6911843  0.06165674]\n"," [0.6780077  0.412466   0.04144444]\n"," [0.891289   0.63395095 0.02103065]\n"," [0.9025091  0.49753556 0.01624199]\n"," [0.9293704  0.7236801  0.01250068]\n"," [0.92470306 0.65199095 0.02768951]]\n"]}]}]}